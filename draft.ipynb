{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Cancer Detection using MLCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.2.3)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for TensorFlow GPU access\n",
    "print(f\"TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "\n",
    "# See TensorFlow version\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installer des bibliothèques et faire les imports nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 1 : Installer les bibliothèques nécessaires\n",
    "%pip install tensorflow\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install pydot\n",
    "%pip install pydot graphviz\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.applications import EfficientNetB0 # type: ignore #ingore the warning\n",
    "from tensorflow.keras.layers import Concatenate, Input, Dense, Dropout, Flatten, GlobalAveragePooling2D # type: ignore #ingore the warning\n",
    "from tensorflow.keras.models import Model, Sequential # type: ignore #ingore the warning\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore #ingore the warning\n",
    "from tensorflow.keras.utils import plot_model # type: ignore #ingore the warning\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array # type: ignore #ingore the warning\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input # type: ignore #ingore the warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition de la fonction de traçage de courbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_training_curves(training, validation, title, subplot):\n",
    "    \"\"\"\n",
    "    Titre: Afficher les courbes d'entraînement\n",
    "\n",
    "    Description:\n",
    "    Cette fonction trace les courbes d'entraînement et de validation pour une métrique donnée (par exemple, précision, perte) au fil des époques.\n",
    "    Elle configure les sous-graphiques, personnalise l'apparence et ajoute des légendes et des étiquettes pour une meilleure visualisation.\n",
    "\n",
    "    Arguments:\n",
    "        training (liste ou tableau): Les points de données d'entraînement à tracer.\n",
    "        validation (liste ou tableau): Les points de données de validation à tracer.\n",
    "        title (str): Le titre du graphique, généralement le nom de la métrique tracée.\n",
    "        subplot (int): L'index du sous-graphe à utiliser pour le graphique actuel (1 ou 2).\n",
    "\n",
    "    Retour:\n",
    "        Aucun\n",
    "    \"\"\"\n",
    "    if subplot == 1:  # set up the subplots on the first call\n",
    "        plt.subplots(figsize=(10, 10), facecolor='#F0F0F0')\n",
    "        plt.tight_layout()\n",
    "    plt.subplot(2, 1, subplot)  # S'assurer d'avoir un bon placement dans la grille (2x1)\n",
    "    plt.gca().set_facecolor('#F8F8F8')  # change the background color\n",
    "    plt.plot(training)\n",
    "    plt.plot(validation)\n",
    "    plt.title('model ' + title)\n",
    "    plt.ylabel(title)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Détecter le hardware à disposition (TPU, GPU ou CPU dans cet ordre de priorité)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect hardware\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
    "except ValueError:\n",
    "  tpu = None\n",
    "#If TPU not found try with GPUs\n",
    "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "    \n",
    "# Select appropriate distribution strategy for hardware\n",
    "if tpu:\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "  print('Running on TPU ', tpu.master())  \n",
    "elif len(gpus) > 0:\n",
    "  strategy = tf.distribute.MirroredStrategy(gpus) # this works for 1 to multiple GPUs\n",
    "  print('Running on ', len(gpus), ' GPU(s) ')\n",
    "else:\n",
    "  strategy = tf.distribute.get_strategy()\n",
    "  print('Running on CPU')\n",
    "\n",
    "# How many accelerators do we have ?\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer un tableau regroupant les chemins des images ainsi que leurs principales caractéristiques (label, âge, sexe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier CSV\n",
    "metadata = pd.read_csv(\"./DataBase/Images/metadata.csv\")\n",
    "\n",
    "# Ajouter le chemin complet des images\n",
    "metadata['image_path'] = metadata['isic_id'].apply(lambda x: f\"./DataBase/Images/{x}.jpg\")\n",
    "\n",
    "# Encoder les labels (0 = benign, 1 = malignant)\n",
    "metadata['label'] = metadata['benign_malignant'].map({'benign': 0, 'malignant': 1})\n",
    "\n",
    "metadata = metadata.dropna(subset=['label'])\n",
    "metadata = metadata[['image_path', 'label', 'age_approx','sex']]\n",
    "print(metadata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des paramètres globaux pour l'entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins vers les fichiers TFRecord (désactivé dans cet exemple)\n",
    "# TRAINING_FILENAMES = tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords/train*')\n",
    "# TEST_FILENAMES = tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords/test*')\n",
    "\n",
    "# Taille des lots adaptée au nombre de répliques (dispositifs GPU/TPU) disponibles\n",
    "BATCH_SIZE = 10 * strategy.num_replicas_in_sync  # Par exemple, 10 images par réplique\n",
    "\n",
    "# Taille des images à utiliser (100x100 pixels)\n",
    "IMAGE_SIZE = [100, 100]  # Taille utilisée pour le redimensionnement des images\n",
    "imSize = 100             # Taille utilisée pour redimensionner les images dans les pipelines\n",
    "\n",
    "# Optimisation automatique pour le préchargement des données\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Nombre d'époques (itérations sur l'ensemble d'entraînement)\n",
    "EPOCHS = 20  # Peut être ajusté en fonction des performances et de la convergence\n",
    "\n",
    "# Définir l'entrée du modèle (couche d'entrée pour TensorFlow/Keras)\n",
    "input_layer = Input(shape=(imSize, imSize, 3))  # Entrée avec une image RGB (3 canaux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des métadonnées, classifications en batch (train, validate, test) et création des dataset TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement et prétraitement des métadonnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du fichier CSV contenant les métadonnées\n",
    "metadata = pd.read_csv(\"./DataBase/Images/metadata.csv\")\n",
    "\n",
    "# Ajouter les chemins complets des images\n",
    "metadata['image_path'] = metadata['isic_id'].apply(lambda x: f\"./DataBase/Images/{x}.jpg\")\n",
    "\n",
    "# Encoder les labels (0 = bénin, 1 = malin)\n",
    "metadata['label'] = metadata['benign_malignant'].map({'benign': 0, 'malignant': 1})\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes\n",
    "metadata = metadata.dropna(subset=['label'])\n",
    "\n",
    "print(f\"Nombre total d'images disponibles : {len(metadata)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division des données en ensembles d’entraînement, validation et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des ensembles en entraînement (70%), validation (20%), et test (10%)\n",
    "train_metadata, temp_metadata = train_test_split(\n",
    "    metadata, \n",
    "    test_size=0.3,  # 30 % seront partagés entre validation et test\n",
    "    stratify=metadata['label'],  # Assurer un équilibre des classes\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "val_metadata, test_metadata = train_test_split(\n",
    "    temp_metadata, \n",
    "    test_size=0.33,  # 1/3 des 30 % pour test, soit ~10 % au total\n",
    "    stratify=temp_metadata['label'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Entraînement : {train_metadata.shape[0]} exemples\")\n",
    "print(f\"Validation : {val_metadata.shape[0]} exemples\")\n",
    "print(f\"Test : {test_metadata.shape[0]} exemples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des fonctions pour charger et prétraiter les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger et prétraiter une image\n",
    "def load_image_and_label(image_path, label):\n",
    "    \"\"\"\n",
    "    Charge une image depuis son chemin, applique des prétraitements\n",
    "    (normalisation, redimensionnement), et retourne l'image et son étiquette.\n",
    "    \"\"\"\n",
    "    # Charger l'image depuis son chemin\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)  # Décode une image JPEG en RGB\n",
    "    \n",
    "    # Normaliser les valeurs des pixels (entre 0 et 1)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    # Redimensionner l'image à une taille standard\n",
    "    image = tf.image.resize(image, [imSize, imSize])\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Fonction pour convertir un DataFrame Pandas en dataset TensorFlow\n",
    "def create_tf_dataset(metadata_df, batch_size):\n",
    "    \"\"\"\n",
    "    Convertit un DataFrame contenant les chemins des images et les étiquettes \n",
    "    en un dataset TensorFlow optimisé pour l'entraînement.\n",
    "    \"\"\"\n",
    "    # Extraction des colonnes nécessaires depuis le DataFrame\n",
    "    image_paths = metadata_df['image_path'].values\n",
    "    labels = metadata_df['label'].values\n",
    "    \n",
    "    # Créer un dataset TensorFlow à partir des chemins et des étiquettes\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    \n",
    "    # Appliquer la fonction de chargement et de prétraitement\n",
    "    dataset = dataset.map(load_image_and_label, num_parallel_calls=AUTO)\n",
    "    \n",
    "    # Diviser en lots et activer le préchargement pour optimiser les performances\n",
    "    dataset = dataset.batch(batch_size).prefetch(AUTO)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des datasets TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer les datasets\n",
    "training_dataset = create_tf_dataset(train_metadata, batch_size=BATCH_SIZE)\n",
    "validation_dataset = create_tf_dataset(val_metadata, batch_size=BATCH_SIZE)\n",
    "test_dataset = create_tf_dataset(test_metadata, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Training dataset : {len(training_dataset)} batches\")\n",
    "print(f\"Validation dataset : {len(validation_dataset)} batches\")\n",
    "print(f\"Test dataset : {len(test_dataset)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des paramètres pour l’entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des paramètres pour l'entraînement\n",
    "STEPS_PER_EPOCH = len(training_dataset)\n",
    "VALIDATION_STEPS = len(validation_dataset)\n",
    "\n",
    "print(f\"Nombre total de lots pour l'entraînement : {STEPS_PER_EPOCH}\")\n",
    "print(f\"Nombre total de lots pour la validation : {VALIDATION_STEPS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cellule en bas à supprimer (version en haut plus à jour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# A SUPPRIMER #\n",
    "###############\n",
    "\n",
    "# Fonction pour charger une image\n",
    "def load_image_and_label(row):\n",
    "    image = tf.io.read_file(row['image_path'])\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    image = tf.image.resize(image, [imSize, imSize])  # Redimensionner\n",
    "    label = row['label']\n",
    "    return image, label\n",
    "\n",
    "# Convertir le DataFrame en dataset\n",
    "def create_tf_dataset(metadata_df, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(metadata_df.to_dict('list'))\n",
    "    dataset = dataset.map(lambda row: load_image_and_label(row), num_parallel_calls=AUTO)\n",
    "    dataset = dataset.batch(batch_size).prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "# Créer des ensembles d'entraînement et de validation\n",
    "training_metadata = metadata.sample(frac=0.8, random_state=42)\n",
    "validation_metadata = metadata.drop(training_metadata.index)\n",
    "print(training_dataset, training_metadata)\n",
    "print(\"Training set: \", training_metadata.shape[0])\n",
    "\n",
    "training_dataset = create_tf_dataset(training_metadata, batch_size=BATCH_SIZE)\n",
    "validation_dataset = create_tf_dataset(validation_metadata, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"Training dataset: \", len(training_dataset))\n",
    "\n",
    "num_batches = sum(1 for _ in training_dataset)\n",
    "print(\"Number of batches:\", num_batches)\n",
    "\n",
    "# Compter le nombre d'images dans chaque ensemble\n",
    "nb_training_images = len(training_dataset)\n",
    "# nb_test_images = count_data_items(TEST_FILENAMES)\n",
    "nb_validation_images = len(validation_dataset)\n",
    "validation_steps = nb_validation_images // BATCH_SIZE\n",
    "STEPS_PER_EPOCH = nb_training_images // BATCH_SIZE \n",
    "\n",
    "print(\"Pattern matches {} data files. Splitting dataset into {} training files and {} validation files\"\n",
    ".format(len(metadata), len(training_dataset), len(validation_dataset)))\n",
    "\n",
    "# print(\"Train dataset: \", training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charger le modèle (sans couche de classification finale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle EfficientNetB0 préentraîné sans la couche de classification finale\n",
    "with strategy.scope():\n",
    "    base_model = tf.keras.Sequential([\n",
    "        EfficientNetB0(\n",
    "            input_shape=(imSize, imSize, 3),\n",
    "            weights='imagenet',\n",
    "            include_top=False\n",
    "        )\n",
    "    ])\n",
    "\n",
    "# Geler les couches du modèle de base pour conserver les poids préentraînés\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passer l'entrée à travers le modèle de base\n",
    "x = base_model(input_layer, training=False)  # `input_layer` \n",
    "x = Flatten()(x)  # Aplatir les caractéristiques extraites\n",
    "\n",
    "\n",
    "# Ajout de couches fully connected pour la classification\n",
    "x = Dense(128, activation=\"relu\")(x)  # Couche dense\n",
    "x = Dropout(0.5)(x)  # Dropout pour régularisation\n",
    "output = Dense(1, activation=\"sigmoid\")(x)  # Sigmoid pour une classification binaire\n",
    "\n",
    "# Définir le modèle final avec une seule entrée (image)\n",
    "model = Model(inputs=input_layer, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiler le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),  # Optimiseur Adam\n",
    "    loss=\"binary_crossentropy\",          # Fonction de perte pour la classification binaire\n",
    "    metrics=[\"accuracy\"]                 # Suivi de la précision\n",
    ")\n",
    "\n",
    "# Résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'architecture du modèle\n",
    "# plot_model(model, show_shapes=True, to_file=\"efficientnetb0_model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_function(epoch):\n",
    "    LR_START = 0.00001 # Taux d'apprentissage initial\n",
    "    LR_MAX = 0.00005 * strategy.num_replicas_in_sync # Taux d'apprentissage maximal\n",
    "    LR_MIN = 0.00001 # Taux d'apprentissage minimal\n",
    "    LR_RAMPUP_EPOCHS = 5 # nombre d'époques pendant lesquelles le taux d'apprentissage augmente linéairement.\n",
    "    LR_SUSTAIN_EPOCHS = 0 # nombre d'époques où le taux reste maximal\n",
    "    LR_EXP_DECAY = .8 # taux de décroissance exponentielle du taux d'apprentissage après les périodes de \"ramp-up\" et de \"soutien\"\n",
    "    \n",
    "\n",
    "    # Augmentation (pour les premières LR_RAMPUP_EPOCHS époques) : le taux d'apprentissage commence à LR_START et monte linéairement jusqu'à LR_MAX\n",
    "    if epoch < LR_RAMPUP_EPOCHS: \n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "\n",
    "    # Soutien (pour les LR_SUSTAIN_EPOCHS suivantes) : le taux d'apprentissage reste constant à LR_MAX\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    # Décroissance (pour les époques restantes) : le taux d'apprentissage diminue exponentiellement\n",
    "    else:\n",
    "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
    "    return lr\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(learning_rate_function, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(training_dataset, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS,\n",
    "                    validation_data=validation_dataset,callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger les matrices Y, Cb, Cr à partir du fichier\n",
    "def load_ycbcr_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Charger les matrices Y, Cb, Cr à partir d'un fichier texte.\n",
    "    Les fichiers doivent contenir trois sections avec des matrices pour chaque composante.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Identifier les sections et extraire les matrices\n",
    "    y_start = lines.index(\"Matrice de luminance (Y):\\n\") + 1\n",
    "    cb_start = lines.index(\"Matrice de chrominance (Cb):\\n\") + 1\n",
    "    cr_start = lines.index(\"Matrice de chrominance (Cr):\\n\") + 1\n",
    "\n",
    "    y = np.loadtxt(lines[y_start:cb_start - 1], dtype=np.float32)\n",
    "    cb = np.loadtxt(lines[cb_start:cr_start - 1], dtype=np.float32)\n",
    "    cr = np.loadtxt(lines[cr_start:], dtype=np.float32)\n",
    "\n",
    "    return y, cb, cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour préparer l'entrée pour le modèle\n",
    "def prepare_ycbcr_input(y, cb, cr):\n",
    "    \"\"\"\n",
    "    Prépare l'entrée pour le modèle à partir des matrices Y, Cb, Cr.\n",
    "    \"\"\"\n",
    "    # Empiler les canaux Y, Cb, Cr pour former une image (100, 100, 3)\n",
    "    image = np.stack([y, cb, cr], axis=-1)  # Shape: (100, 100, 3)\n",
    "\n",
    "    # Normaliser l'image (en utilisant une normalisation simple, pas celle d'ImageNet)\n",
    "    image = image / 255.0  # Normalisation simple entre 0 et 1\n",
    "\n",
    "    # Ajouter la dimension du batch (1, 100, 100, 3)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de prédiction\n",
    "def predict_skin_cancer(file_path):\n",
    "    \"\"\"\n",
    "    Prédire à partir des matrices Y, Cb, Cr chargées depuis un fichier.\n",
    "    \"\"\"\n",
    "    # Charger les matrices Y, Cb, Cr à partir du fichier\n",
    "    y, cb, cr = load_ycbcr_from_file(file_path)\n",
    "\n",
    "    # Préparer l'entrée pour le modèle\n",
    "    ycbcr_input = prepare_ycbcr_input(y, cb, cr)\n",
    "\n",
    "\n",
    "    # Prédiction\n",
    "    prediction = model.predict(ycbcr_input)\n",
    "\n",
    "    # Interprétation\n",
    "    if prediction[0] > 0.5:\n",
    "        return f\"Maligne (probabilité {prediction[0][0]:.2f})\"\n",
    "    else:\n",
    "        return f\"Bénigne (probabilité {1 - prediction[0][0]:.2f})\"\n",
    "\n",
    "# Exemple d'utilisation\n",
    "file_path = \"./DataBase/Matrices/ISIC_0001120_matrices.txt\"\n",
    "result = predict_skin_cancer(file_path)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_tensorflow)",
   "language": "python",
   "name": "venv_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
