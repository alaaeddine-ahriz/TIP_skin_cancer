{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection des mélanomes par apprentissage machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Ce notebook présente le développement d’un modèle d’apprentissage machine pour classifier les lésions cutanées en `bénignes` ou `maligne`. Le dataset utilisé provient de l’ISIC (International Skin Imaging Collaboration). Le projet s’appuie sur le transfer learning avec le modèle EfficientNet. Les étapes incluent le prétraitement des données, l’implémentation du modèle, l’entraînement et l’évaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des bibliothèques\n",
    "Nous commençons par installer et importer les bibliothèques nécessaires pour notre projet. Ces bibliothèques permettent de manipuler les données, d’afficher des visualisations et de créer le modèle d’apprentissage. Les principales bibliothèques utilisées sont :\n",
    "- `numpy` et `pandas` pour la manipulation des données,\n",
    "- `tensorflow.keras` pour la construction du modèle,\n",
    "- d’autres modules spécifiques pour le prétraitement et la visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312 (from tensorflow-intel==2.18.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312 (from tensorflow-intel==2.18.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: rich in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312 (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pydot in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydot) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pydot in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.20.3)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydot) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mikai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install pydot\n",
    "%pip install pydot graphviz\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.applications import EfficientNetB0 # type: ignore #ingore the warning\n",
    "from tensorflow.keras.layers import Concatenate, Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D,GlobalAveragePooling2D # type: ignore #ingore the warning\n",
    "from tensorflow.keras.models import Model, Sequential # type: ignore #ingore the warning\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore #ingore the warning\n",
    "from tensorflow.keras.utils import plot_model # type: ignore #ingore the warning\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array # type: ignore #ingore the warning\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input # type: ignore #ingore the warning\n",
    "from tensorflow.keras.callbacks import TensorBoard # type: ignore #ingore the warning\n",
    "from tensorflow.keras.metrics import Precision, Recall, Metric # type: ignore #ingore the warning\n",
    "from keras.saving import register_keras_serializable # type: ignore #ingore the warning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Détection du matériel (TPU, GPU, CPU)\n",
    "\n",
    "Cette cellule détecte le matériel disponible (TPU, GPU ou CPU) et configure une stratégie adaptée pour optimiser l'entraînement :\n",
    "\n",
    "1. **Priorité** : TPU > GPU > CPU.\n",
    "2. **Stratégie de distribution des calculs** :\n",
    "   - TPU : Utilisation de `TPUStrategy` pour exécutions distribuées.\n",
    "   - GPU : Utilisation de `MirroredStrategy` pour un ou plusieurs GPU.\n",
    "   - CPU : Stratégie par défaut si pas de TPU ou GPU disponible.\n",
    "3. **Ressources synchronisées** : Le nombre de répliques (`strategy.num_replicas_in_sync`) sera utilisé pour ajuster dynamiquement la taille globale du batch.\n",
    "\n",
    "Cette configuration optimise l'utilisation des ressources matérielles (en puissance de calcul) disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CPU\n",
      "Number of accelerators:  1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
    "except ValueError:\n",
    "  tpu = None\n",
    "#If TPU not found try with GPUs\n",
    "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "    \n",
    "# Select appropriate distribution strategy for hardware\n",
    "if tpu:\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "  print('Running on TPU ', tpu.master())  \n",
    "elif len(gpus) > 0:\n",
    "  strategy = tf.distribute.MirroredStrategy(gpus) # this works for 1 to multiple GPUs\n",
    "  print('Running on ', len(gpus), ' GPU(s) ')\n",
    "else:\n",
    "  strategy = tf.distribute.get_strategy()\n",
    "  print('Running on CPU')\n",
    "\n",
    "# How many accelerators do we have ?\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFRECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Retourne une fonction de type tf.train.Feature pour une valeur binaire (image).\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Retourne une fonction de type tf.train.Feature pour une valeur entière (label).\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def image_example(image, label):\n",
    "    \"\"\"Convertit une image et un label en un format tf.train.Example.\"\"\"\n",
    "    feature = {\n",
    "        'image': _bytes_feature(image),\n",
    "        'label': _int64_feature(label)\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "def write_tfrecords(metadata_df, output_path):\n",
    "\n",
    "    if not os.path.exists('tfrecords'):\n",
    "        os.makedirs('tfrecords')\n",
    "    \n",
    "    \"\"\"Crée un fichier TFRecord à partir du DataFrame contenant les chemins des images et les labels.\"\"\"\n",
    "    with tf.io.TFRecordWriter(output_path) as writer:\n",
    "        for _, row in metadata_df.iterrows():\n",
    "            # Charger l'image à partir du chemin\n",
    "            image_path = row['image_path']\n",
    "            image = tf.io.read_file(image_path)\n",
    "            image = tf.image.decode_jpeg(image, channels=3)  # Décode l'image au format JPEG\n",
    "            \n",
    "            # Récupérer l'étiquette\n",
    "            label = row['label']\n",
    "            \n",
    "            # Convertir l'image et l'étiquette en un example TFRecord\n",
    "            tf_example = image_example(image, label)\n",
    "            \n",
    "            # Écrire l'exemple dans le fichier TFRecord\n",
    "            writer.write(tf_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition des paramètres globaux pour l'entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins vers les fichiers TFRecord (désactivé dans cet exemple)\n",
    "# TRAINING_FILENAMES = tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords/train*')\n",
    "# TEST_FILENAMES = tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords/test*')\n",
    "\n",
    "# Taille des lots adaptée au nombre de répliques (dispositifs GPU/TPU) disponibles\n",
    "\n",
    "##################################\n",
    "# rajout conidtion si GPU ou TPU #\n",
    "##################################\n",
    "BATCH_SIZE = 32 * strategy.num_replicas_in_sync  # Par exemple, 10 images par réplique\n",
    "\n",
    "# Taille des images à utiliser (100x100 pixels)\n",
    "IMAGE_SIZE = [100, 100]  # Taille utilisée pour le redimensionnement des images\n",
    "imSize = 100             # Taille utilisée pour redimensionner les images dans les pipelines\n",
    "\n",
    "# Optimisation automatique pour le préchargement des données\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Nombre d'époques (itérations sur l'ensemble d'entraînement)\n",
    "EPOCHS = 40  # Peut être ajusté en fonction des performances et de la convergence\n",
    "\n",
    "# Définir l'entrée du modèle (couche d'entrée pour TensorFlow/Keras)\n",
    "input_layer = Input(shape=(imSize, imSize, 3))  # Entrée avec une image RGB (3 canaux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données\n",
    "Les données, composées d’images et de métadonnées, sont chargées depuis un fichier CSV contenant les informations associées. Ces métadonnées incluent notamment :\n",
    "- le label `benign_malignant` (notre variable cible),\n",
    "- des informations sur le patient et la lésion.\n",
    "\n",
    "L’affichage des premières lignes du fichier nous permet de vérifier sa structure et son contenu avant toute manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total d'images disponibles : 5991\n",
      "Total rows in original CSV: 5991\n",
      "Nombre total d'images disponibles : 3994\n",
      "Nombre total d'images disponibles : 10000\n"
     ]
    }
   ],
   "source": [
    "# Chargement du fichier CSV contenant les métadonnées\n",
    "metadata = pd.read_csv(\"./Data/benign/cutout/metadata.csv\",encoding='ISO-8859-1', sep=';')\n",
    "metadata_norm = pd.read_csv(\"./Data/benign/metadata.csv\",encoding='ISO-8859-1', sep=';')\n",
    "metadata_clinique = pd.read_csv(\"./Data/train.csv\")\n",
    "# Ajouter les chemins complets des images\n",
    "\n",
    "metadata['image_path'] = metadata['isic_id'].apply(lambda x: f\"./Data/benign/cutout/{x}.jpg\")\n",
    "metadata['label'] = metadata['benign_malignant'].map({'benign': 0, 'malignant': 1})\n",
    "\n",
    "metadata_clinique['image_path'] = metadata_clinique['image_name'].apply(lambda x: f\"./Data/train/{x}.jpg\")\n",
    "metadata_clinique['label'] = metadata_clinique['benign_malignant'].map({'benign': 0, 'malignant': 1})\n",
    "\n",
    "metadata_norm['image_path'] = metadata_norm['isic_id'].apply(lambda x: f\"./Data/benign/{x}.jpg\")\n",
    "metadata_norm['label'] = metadata_norm['benign_malignant'].map({'benign': 0, 'malignant': 1})\n",
    "\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes\n",
    "metadata = metadata.dropna(subset=['label'])\n",
    "metadata_norm = metadata_norm.dropna(subset=['label'])\n",
    "metadata_clinique = metadata_clinique.dropna(subset=['label'])\n",
    "\n",
    "metadata_clinique = metadata_clinique.sample(n=10000,random_state=42)\n",
    "\n",
    "# Utiliser 50% des données normales pour l'entraînement\n",
    "metadata_train = metadata_norm.sample(frac=0.5, random_state=42)\n",
    "\n",
    "# Utiliser les 50% restants de metadata_norm pour le test\n",
    "metadata_test2 = metadata_norm.drop(metadata_train.index)\n",
    "\n",
    "# Concatenation de metadata (cutout) et metadata_train (50% des données normales) pour l'entraînement\n",
    "metadata = pd.concat([metadata, metadata_train], ignore_index=True)\n",
    "\n",
    "metadata = metadata [['image_path', 'label']]\n",
    "\n",
    "metadata_clinique = metadata_clinique [['image_path', 'label']]\n",
    "\n",
    "print(f\"Nombre total d'images disponibles : {len(metadata)}\")\n",
    "print(f\"Total rows in original CSV: {metadata.shape[0]}\")\n",
    "\n",
    "print(f\"Nombre total d'images disponibles : {len(metadata_norm)}\")\n",
    "\n",
    "print(f\"Nombre total d'images disponibles : {len(metadata_clinique)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    4457\n",
      "1    1534\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    4457\n",
      "1    1534\n",
      "Name: count, dtype: int64\n",
      "Nombre d'images après échantillonnage : 5991\n"
     ]
    }
   ],
   "source": [
    "# Affiche le nombre  d'images par classe\n",
    "print(metadata['label'].value_counts())\n",
    "\n",
    "# Prendre un échantillon aléatoire de 10 000 images\n",
    "# metadata = metadata.sample(n=5000, random_state=42)\n",
    "print(metadata['label'].value_counts())\n",
    "# Afficher la taille du nouvel échantillon\n",
    "print(f\"Nombre d'images après échantillonnage : {len(metadata)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Division des données en ensembles d’entraînement, validation et test\n",
    "À cette étape, les données sont divisées en trois ensembles distincts : entraînement, validation, et test, afin de préparer le modèle pour son entraînement et son évaluation. Tout d'abord, 70 % des données sont affectées à l'ensemble d'entraînement, qui sera utilisé pour ajuster les paramètres du modèle. Les 30 % restants sont répartis entre les ensembles de validation (20 % des données totales) et de test (10 % des données totales). La stratification est appliquée sur la variable label pour garantir que les proportions des classes (par exemple, \"Malignant\" et \"Benign\") sont similaires dans les trois ensembles. Cette méthode assure une représentation équilibrée des classes dans chaque ensemble, ce qui est essentiel pour éviter les biais dans l'évaluation des performances du modèle.\n",
    "\n",
    "La stratification consiste à répartir les données de manière à ce que la proportion de chaque classe soit conservée dans les sous-ensembles créés (entraînement, validation, test). Cela garantit que les ensembles reflètent fidèlement la distribution initiale des classes, évitant les déséquilibres qui pourraient biaiser l'entraînement ou l'évaluation du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement : 4193 exemples\n",
      "Validation : 1198 exemples\n",
      "Test : 600 exemples\n"
     ]
    }
   ],
   "source": [
    "# Mélanger les données initiales\n",
    "metadata = metadata.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Division des ensembles en entraînement (70%), validation (20%), et test (10%)\n",
    "# training_metadata = metadata.sample(frac=0.8, random_state=42)\n",
    "# validation_metadata = metadata.drop(training_metadata.index)\n",
    "train_size = int(0.7 * len(metadata))  # 70% pour l'entraînement\n",
    "val_size = int(0.2 * len(metadata))    # 20% pour la validation\n",
    "test_size = len(metadata) - train_size - val_size  # 10% pour le test\n",
    "\n",
    "training_metadata = metadata.iloc[:train_size]\n",
    "validation_metadata = metadata.iloc[train_size:train_size + val_size]\n",
    "test_metadata = metadata.iloc[train_size + val_size:]\n",
    "\n",
    "print(f\"Entraînement : {training_metadata.shape[0]} exemples\")\n",
    "print(f\"Validation : {validation_metadata.shape[0]} exemples\")\n",
    "print(f\"Test : {test_metadata.shape[0]} exemples\")\n",
    "\n",
    "####################################################################################\n",
    "# ??? Ajouter la fonction de création des datasets pour TensorFlow juste après ??? #\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérifications des datasets\n",
    "\n",
    "Cette étape on vérifie la cohérence après la division des données :\n",
    "\n",
    "1. **Distribution des classes** : Vérification que les proportions de classes (`benign`/`malignant`) sont respectées dans chaque ensemble.\n",
    "2. **Taille totale** : Validation que la somme des échantillons des trois ensembles correspond au dataset initial.\n",
    "3. **Absence de chevauchements** : Contrôle qu’aucun échantillon ne se trouve dans plusieurs ensembles, évitant les problèmes de fuite de données (`data leakage`).\n",
    "\n",
    "Toute incohérence déclenche une erreur pour correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set:\n",
      "label\n",
      "0    0.749583\n",
      "1    0.250417\n",
      "Name: proportion, dtype: float64\n",
      "Class distribution in validation set:\n",
      "label\n",
      "0    0.736227\n",
      "1    0.263773\n",
      "Name: proportion, dtype: float64\n",
      "Class distribution in test set:\n",
      "label\n",
      "0    0.72\n",
      "1    0.28\n",
      "Name: proportion, dtype: float64\n",
      "Total samples: 5991 (original: 5991)\n"
     ]
    }
   ],
   "source": [
    "print(\"Class distribution in training set:\")\n",
    "print(training_metadata['label'].value_counts(normalize=True))\n",
    "print(\"Class distribution in validation set:\")\n",
    "print(validation_metadata['label'].value_counts(normalize=True))\n",
    "print(\"Class distribution in test set:\")\n",
    "print(test_metadata['label'].value_counts(normalize=True))\n",
    "\n",
    "total_samples = training_metadata.shape[0] + validation_metadata.shape[0] + test_metadata.shape[0]\n",
    "print(f\"Total samples: {total_samples} (original: {metadata.shape[0]})\")\n",
    "\n",
    "# Check pour des overlaps entre les sets de données (data leakage), retourne une erreur si overlap\n",
    "assert len(set(training_metadata.index) & set(validation_metadata.index)) == 0, \"Overlap between train and validation sets!\"\n",
    "# assert len(set(val_metadata.index) & set(test_metadata.index)) == 0, \"Overlap between validation and test sets!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de labels bénins : 168\n"
     ]
    }
   ],
   "source": [
    "malign_count = len(test_metadata[test_metadata['label'] == 1])\n",
    "# Afficher le résultat\n",
    "print(f\"Nombre de labels bénins : {malign_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des fonctions pour charger et prétraiter les données\n",
    "À cette étape, le code prépare un pipeline de traitement des images pour l'entraînement du modèle. Les images sont chargées à partir de leurs chemins, redimensionnées à une taille standard de 100x100 pixels, normalisées (valeurs entre 0 et 1), et associées à leurs étiquettes (labels). Ces transformations sont encapsulées dans une fonction `load_image_and_label`, appliquée via `tf.data.Dataset` pour créer un ensemble de données TensorFlow optimisé. Enfin, les données sont divisées en lots et préchargées pour accélérer l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger et prétraiter une image\n",
    "def load_image_and_label(image_path, label):\n",
    "    \"\"\"\n",
    "    Charge une image depuis son chemin, applique des prétraitements\n",
    "    (normalisation, redimensionnement), et retourne l'image et son étiquette.\n",
    "    \"\"\"\n",
    "    # Charger l'image depuis son chemin\n",
    "    image = tf.io.read_file(image_path)  # Lire le fichier image\n",
    "    image = tf.image.decode_jpeg(image, channels=3)  # Décode une image JPEG en RGB\n",
    "    \n",
    "    # Normaliser les valeurs des pixels (entre 0 et 1)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    # Redimensionner l'image à une taille standard\n",
    "    image = tf.image.resize(image, [imSize, imSize])\n",
    "\n",
    "    label = tf.cast(label, tf.int64)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Fonction pour convertir un DataFrame Pandas en dataset TensorFlow\n",
    "def create_tf_dataset(metadata_df, batch_size):\n",
    "    \"\"\"\n",
    "    Convertit un DataFrame contenant les chemins des images et les labels \n",
    "    en un dataset TensorFlow optimisé pour l'entraînement.\n",
    "    \"\"\"\n",
    "    # Extraction des colonnes nécessaires depuis le DataFrame\n",
    "    image_paths = metadata_df['image_path'].values\n",
    "    labels = metadata_df['label'].values\n",
    "    \n",
    "    # Créer un dataset TensorFlow à partir des chemins et des étiquettes\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        lambda image_path, label: load_image_and_label(image_path, label),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    \n",
    "    # Appliquer la fonction de chargement et de prétraitement à chaque image du dataset\n",
    "    # dataset = dataset.map(load_image_and_label, num_parallel_calls=AUTO)\n",
    "    \n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "    dataset = dataset.shuffle(1500)  # Mélange avec un tampon de 1500 éléments\n",
    "\n",
    "    # Diviser en lots et activer le préchargement pour optimiser les performances\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset= dataset.prefetch(AUTO)\n",
    "\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def create_tf_test_dataset(metadata_df, batch_size):\n",
    "    \"\"\"\n",
    "    Convertit un DataFrame contenant les chemins des images et les labels \n",
    "    en un dataset TensorFlow optimisé pour l'entraînement.\n",
    "    \"\"\"\n",
    "    # Extraction des colonnes nécessaires depuis le DataFrame\n",
    "    image_paths = metadata_df['image_path'].values\n",
    "    labels = metadata_df['label'].values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(metadata_df.to_dict('list'))\n",
    "    \n",
    "    # Créer un dataset TensorFlow à partir des chemins et des étiquettes\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        lambda image_path, label: load_image_and_label(image_path, label),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    # Diviser en lots et activer le préchargement pour optimiser les performances\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset= dataset.prefetch(AUTO)\n",
    "\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créations des TFrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_tfrecord(proto):\n",
    "    \"\"\"Fonction pour décoder un exemple à partir du fichier TFRecord.\"\"\"\n",
    "    # Description de l'exemple dans le fichier TFRecord\n",
    "    description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    \n",
    "    # Parser l'exemple\n",
    "    parsed_features = tf.io.parse_single_example(proto, description)\n",
    "    \n",
    "    # Décoder l'image\n",
    "    image = tf.io.decode_jpeg(parsed_features['image'], channels=3)\n",
    "    # Redimensionner l'image\n",
    "    image = tf.image.resize(image, [imSize, imSize])\n",
    "    # Normaliser l'image\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    label = parsed_features['label']\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def create_tf_dataset_from_tfrecord(tfrecord_files, batch_size):\n",
    "    \"\"\"Charge un dataset à partir des fichiers TFRecord.\"\"\"\n",
    "    # Créer un dataset à partir des fichiers TFRecord\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "    \n",
    "    # Parser les éléments du TFRecord\n",
    "    dataset = dataset.map(_parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Appliquer les transformations (mélange, regroupement en lots, etc.)\n",
    "    dataset = dataset.shuffle(1500).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test d'affichage de quelques images du dataset (depuis le pipeline TensorFlow)\n",
    "Cette étape permet de vérifier si les images ont été correctement redimensionnées en prenant aléatoirement 5 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualiser 5 images aléatoires depuis le pipeline TensorFlow\n",
    "# for image, label in create_tf_dataset(metadata.sample(frac=1).reset_index(drop=True), batch_size=1).take(5):\n",
    "#     # Convertir le tenseur en tableau NumPy pour l'affichage\n",
    "#     img_resized = image[0].numpy()\n",
    "#     plt.imshow(img_resized)\n",
    "#     # Afficher le label avec le mapping 0 -> Benign, 1 -> Malignant\n",
    "#     plt.title(f\"{'Benign' if label.numpy() == 0 else 'Malignant'}\")\n",
    "#     plt.axis('off')  # Supprimer les axes pour une meilleure visualisation\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création des datasets TensorFlow\n",
    "\n",
    "Cette étape transforme les sous-ensembles (entraînement, validation et test) en pipelines optimisés pour TensorFlow à l'aide de create_tf_dataset. Chaque dataset contient des images prétraitées (chargées, redimensionnées, et normalisées) associées à leurs labels, regroupées en lots de taille spécifiée (BATCH_SIZE). Ces datasets sont utilisés directement par le modèle lors de l'entraînement ou de l'évaluation pour assurer une gestion efficace des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer les datasets\n",
    "training_dataset = create_tf_dataset(training_metadata, batch_size=BATCH_SIZE)\n",
    "validation_dataset = create_tf_dataset(validation_metadata, batch_size=BATCH_SIZE)\n",
    "test_dataset = create_tf_test_dataset(test_metadata, batch_size=BATCH_SIZE)\n",
    "test2_dataset = create_tf_test_dataset(metadata_test2, batch_size=BATCH_SIZE)\n",
    "test3_dataset = create_tf_test_dataset(metadata_clinique, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "# Créer les fichiers TFRecord pour chaque partie de votre dataset\n",
    "# write_tfrecords(training_metadata, 'tfrecords/train.tfrecords')\n",
    "# write_tfrecords(validation_metadata, 'tfrecords/val.tfrecords')\n",
    "# # write_tfrecords(test_metadata, 'test.tfrecords')\n",
    "\n",
    "# # Utiliser les fichiers TFRecord pour créer les datasets\n",
    "# training_dataset = create_tf_dataset_from_tfrecord(['tfrecords/train.tfrecords'], batch_size=BATCH_SIZE)\n",
    "# validation_dataset = create_tf_dataset_from_tfrecord(['tfrecords/val.tfrecords'], batch_size=BATCH_SIZE)\n",
    "# test_dataset = create_tf_dataset_from_tfrecord(['test.tfrecords.tfrec'], batch_size=BATCH_SIZE)\n",
    "\n",
    "# print(f\"Test dataset : {len(test_dataset)}\")\n",
    "# print(f\"Test dataset : {len(test_dataset)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul des paramètres pour l’entraînement\n",
    "Les paramètres STEPS_PER_EPOCH et VALIDATION_STEPS déterminent le nombre de lots nécessaires pour parcourir une fois l'ensemble des données d'entraînement ou de validation. Ils sont calculés en divisant la taille totale des données par BATCH_SIZE pour garantir que le modèle traite toutes les données à chaque époque, tout en optimisant l'utilisation des ressources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'étapes pour l'entraînement : 131\n",
      "Nombre d'étapes pour la validation : 37\n"
     ]
    }
   ],
   "source": [
    "# Calcul des paramètres pour l'entraînement\n",
    "# STEPS_PER_EPOCH = len(training_dataset) // BATCH_SIZE\n",
    "# VALIDATION_STEPS = len(validation_dataset) // BATCH_SIZE \n",
    "steps_per_epochs = len(training_metadata) // BATCH_SIZE\n",
    "validation_steps = len(validation_metadata) // BATCH_SIZE\n",
    "\n",
    "print(f\"Nombre d'étapes pour l'entraînement : {steps_per_epochs}\")\n",
    "print(f\"Nombre d'étapes pour la validation : {validation_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction du modèle\n",
    "### Chargement du modèle pré-entraîné\n",
    "Nous utilisons `EfficientNetB0`, un modèle convolutionnel pré-entraîné sur ImageNet. Les couches internes, qui extraient les caractéristiques générales des images, sont gelées, tandis que la dernière couche de classification est remplacée pour s’adapter à notre tâche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle EfficientNetB0 préentraîné sans la couche de classification finale\n",
    "\n",
    "base_model = EfficientNetB0(\n",
    "            input_shape=(imSize, imSize, 3),\n",
    "            weights='imagenet',\n",
    "            include_top=False\n",
    "        )\n",
    "# Geler les couches du modèle de base pour conserver les poids préentraînés\n",
    "base_model.trainable = True # On réalise du fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passer l'entrée à travers le modèle de base\n",
    "x = base_model(input_layer, training=True)  # `input_layer` \n",
    "\n",
    "# Ajouter des couches convolutionnelles et de pooling\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "\n",
    "# Aplatir les caractéristiques extraites\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Ajouter des couches fully connected avec dropout\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(x)  # Sigmoid pour une classification binaire\n",
    "\n",
    "\n",
    "# Définir le modèle final avec une seule entrée (image)\n",
    "model = Model(inputs=input_layer, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation du modèle\n",
    "\n",
    "Cette étape configure le modèle pour l’entraînement en définissant l’optimiseur, la fonction de perte et les métriques à suivre. Après la compilation, un résumé du modèle est affiché pour vérifier la structure des couches, le nombre de paramètres et la compatibilité des dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,949,376</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m2,949,376\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m525,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,401,764</span> (35.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,401,764\u001b[0m (35.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,359,741</span> (35.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,359,741\u001b[0m (35.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,023</span> (164.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m42,023\u001b[0m (164.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcul des poids des classes pour l'entraînement\n",
    "\n",
    "\n",
    "# benin_weight = len(training_metadata) / len(test_metadata[test_metadata['label'] == 0])\n",
    "# malin_weight = len(training_metadata) / len(test_metadata[test_metadata['label'] == 1])\n",
    "\n",
    "# print(f\"Poids de la classe bénigne : {benin_weight:.2f}\")\n",
    "# print(f\"Poids de la classe maligne : {malin_weight:.2f}\")\n",
    "\n",
    "class_weights = {0: 1, 1: 1}  # Augmenter le poids de la classe \"malin\"\n",
    "\n",
    "@register_keras_serializable()\n",
    "# Définition d'une métrique F1 personnalisée\n",
    "class F1Score(Metric):\n",
    "    def __init__(self, name=\"f1_score\", **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',  # Optimiseur Adam\n",
    "    loss=\"binary_crossentropy\",          # Fonction de perte pour la classification binaire\n",
    "    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score()]  # Suivi de la précision\n",
    ")\n",
    "\n",
    "# Résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'architecture du modèle\n",
    "# plot_model(model, show_shapes=True, to_file=\"efficientnetb0_model.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduler pour le Learning Rate\n",
    "Le modèle est entraîné sur l’ensemble d’entraînement, avec un suivi sur l’ensemble de validation. Un learning rate dynamique est utilisé, évoluant selon les phases suivantes :\n",
    "1. Augmentation progressive jusqu’à un seuil maximal.\n",
    "2. Stabilisation au maximum pendant une durée définie.\n",
    "3. Réduction exponentielle jusqu’à un seuil minimal.\n",
    "\n",
    "Ce mécanisme permet une convergence optimale et une meilleure généralisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_function(epoch):\n",
    "    LR_START = 0.000005 # Taux d'apprentissage initial\n",
    "    LR_MAX = 0.000005 * strategy.num_replicas_in_sync # Taux d'apprentissage maximal\n",
    "    LR_MIN = 0.000001 # Taux d'apprentissage minimal\n",
    "    LR_RAMPUP_EPOCHS = 3 # nombre d'époques pendant lesquelles le taux d'apprentissage augmente linéairement.\n",
    "    LR_SUSTAIN_EPOCHS = 0 # nombre d'époques où le taux reste maximal\n",
    "    LR_EXP_DECAY = .8 # taux de décroissance exponentielle du taux d'apprentissage après les périodes de \"ramp-up\" et de \"soutien\"\n",
    "    \n",
    "\n",
    "    # Augmentation (pour les premières LR_RAMPUP_EPOCHS époques) : le taux d'apprentissage commence à LR_START et monte linéairement jusqu'à LR_MAX\n",
    "    if epoch < LR_RAMPUP_EPOCHS: \n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "\n",
    "    # Soutien (pour les LR_SUSTAIN_EPOCHS suivantes) : le taux d'apprentissage reste constant à LR_MAX\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    # Décroissance (pour les époques restantes) : le taux d'apprentissage diminue exponentiellement\n",
    "    else:\n",
    "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
    "    return lr\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(learning_rate_function, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\n",
    "#     \"models/fine-tunning_40epochs.keras\",\n",
    "#     custom_objects={\"F1Score\": F1Score}\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrement des logs avec TensorBoard et entraînement du modèle\n",
    "Le modèle est entraîné tout en enregistrant les métriques dans TensorBoard pour un suivi en temps réel. On note les particularités suivantes:\n",
    "- pour **TensorBoard** : Les logs sont enregistrés dans `logs/fit/model_name`, avec les histogrammes des poids activés (`histogram_freq=1`),\n",
    "- pour l'**entraînement** : Le modèle utilise les ensembles d’entraînement et de validation, avec les callbacks suivants :\n",
    "  - `lr_schedule` pour ajuster dynamiquement le learning rate.\n",
    "  - `tensorboard_callback` pour visualiser les métriques dans TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 5e-06.\n",
      "Epoch 1/40\n",
      "\u001b[1m 69/131\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 472ms/step - accuracy: 0.5175 - f1_score: 0.2882 - loss: 0.7005 - precision: 0.2194 - recall: 0.4365"
     ]
    }
   ],
   "source": [
    "log_dir = os.path.join(\"logs\", \"fit\", \"model_name\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(training_dataset, steps_per_epoch=steps_per_epochs, epochs=EPOCHS,\n",
    "                    validation_data=validation_dataset, validation_steps=validation_steps,callbacks=[lr_schedule,tensorboard_callback],class_weight=class_weights,)\n",
    "\n",
    "# tensorboard --logdir=logs/fit pour lancer TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Sauvegarder les données d'history\n",
    "with open('history.json', 'w') as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation et analyse des performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage des courbes d'entraînement et de validation\n",
    "Cette section génère et affiche les courbes d'évolution des métriques (`accuracy` et `loss`) au fil des époques pour évaluer les performances du modèle. Cela nous permet d’analyser :\n",
    "- La convergence du modèle sur les données d'entraînement.\n",
    "- La généralisation sur les données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot accuracy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracy\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Precision, Recall, and F1-Score\n",
    "plt.figure(figsize=(8, 4))\n",
    "if 'precision' in history.history and 'val_precision' in history.history:\n",
    "    plt.plot(history.history['precision'], label='Train Precision')\n",
    "    plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "\n",
    "if 'recall' in history.history and 'val_recall' in history.history:\n",
    "    plt.plot(history.history['recall'], label='Train Recall')\n",
    "    plt.plot(history.history['val_recall'], label='Validation Recall')\n",
    "\n",
    "if 'f1_score' in history.history and 'val_f1_score' in history.history:\n",
    "    plt.plot(history.history['f1_score'], label='Train F1-Score')\n",
    "    plt.plot(history.history['val_f1_score'], label='Validation F1-Score')\n",
    "\n",
    "plt.title('Model Metrics (Precision, Recall, F1-Score)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction sur de nouvelles données\n",
    "\n",
    "Cette section utilise le modèle entraîné pour prédire la classe (`benign` ou `malignant`) d'une image donnée. L'image est prétraitée pour correspondre au format attendu par le modèle, et la classe prédite est accompagnée d'une probabilité de confiance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédire les résultats sur le dataset de test\n",
    "predictions = model.predict(test2_dataset)\n",
    "\n",
    "# Classification binaire (sigmoid), les prédictions sont des probabilités\n",
    "predicted_probabilities = predictions.flatten()\n",
    "\n",
    "# Convertir les probabilités en classes binaires (0 ou 1)\n",
    "predicted_classes = (predicted_probabilities >= 0.5).astype(int)\n",
    "\n",
    "# Calculer l'accuracy globale\n",
    "true_labels = metadata_test2['label'].values  # Étiquettes réelles\n",
    "accuracy = (predicted_classes == true_labels).mean()\n",
    "print(f\"Accuracy globale : {accuracy:.2%}\")\n",
    "\n",
    "# Calculer le nombre de bénins (classe 0) et malins (classe 1) correctement prédits\n",
    "benign_correct = ((predicted_classes == 0) & (true_labels == 0)).sum()\n",
    "malignant_correct = ((predicted_classes == 1) & (true_labels == 1)).sum()\n",
    "\n",
    "# Nombre total de bénins et malins dans le dataset\n",
    "benign_total = (true_labels == 0).sum()\n",
    "malignant_total = (true_labels == 1).sum()\n",
    "\n",
    "# Taux de réussite pour chaque classe\n",
    "benign_accuracy = benign_correct / benign_total if benign_total > 0 else 0\n",
    "malignant_accuracy = malignant_correct / malignant_total if malignant_total > 0 else 0\n",
    "\n",
    "#Calculer les faux positifs (prédits comme 1 mais étiquetés 0) et les faux négatifs (prédits comme 0 mais étiquetés 1)\n",
    "false_positives = ((predicted_classes == 1) & (true_labels == 0)).sum()\n",
    "false_negatives = ((predicted_classes == 0) & (true_labels == 1)).sum()\n",
    "\n",
    "print(f\"Nombre total de cas bénins : {benign_total}, Prédits correctement : {benign_correct}, Taux de réussite : {benign_accuracy:.2%}\")\n",
    "print(f\"Nombre total de cas malins : {malignant_total}, Prédits correctement : {malignant_correct}, Taux de réussite : {malignant_accuracy:.2%}\")\n",
    "\n",
    "\n",
    "print(f\"Faux positifs (prédits malins, mais bénins) : {false_positives}\")\n",
    "print(f\"Faux négatifs (prédits bénins, mais malins) : {false_negatives}\")\n",
    "\n",
    "# Tracer un histogramme des probabilités pour toutes les prédictions\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(predicted_probabilities, bins=20, color='lightcoral', edgecolor='black')\n",
    "plt.title('Distribution des probabilités des prédictions (toutes les images)')\n",
    "plt.xlabel('Probabilité prédite')\n",
    "plt.ylabel('Nombre d\\'exemples')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Nombre d'exemples prédits comme classe 1\n",
    "num_class_1 = (predicted_probabilities >= 0.5).sum()\n",
    "print(f\"Nombre d'exemples prédits comme classe 1 : {num_class_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Courbe ROC\n",
    "# Récupérer les scores de prédiction (probabilités pour la classe positive)\n",
    "y_score = predictions.ravel()  # Pour binaire\n",
    "\n",
    "# Extraire les labels vrais (en supposant que 'label' soit une colonne de test_metadata)\n",
    "y_true = metadata_test2['label'].values  # C'est un tableau 1D des étiquettes de classe\n",
    "\n",
    "print(y_score)\n",
    "print(y_true)\n",
    "\n",
    "# Calcul de la courbe ROC\n",
    "fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Tracer la courbe ROC\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guess')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
