{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection des mélanomes par apprentissage machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Ce notebook présente le développement d’un modèle d’apprentissage machine pour classifier les lésions cutanées en `bénignes` ou `maligne`. Le dataset utilisé provient de l’ISIC (International Skin Imaging Collaboration). Le projet s’appuie sur le transfer learning avec le modèle EfficientNet. Les étapes incluent le prétraitement des données, l’implémentation du modèle, l’entraînement et l’évaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des bibliothèques\n",
    "Nous commençons par installer et importer les bibliothèques nécessaires pour notre projet. Ces bibliothèques permettent de manipuler les données, d’afficher des visualisations et de créer le modèle d’apprentissage. Les principales bibliothèques utilisées sont :\n",
    "- `numpy` et `pandas` pour la manipulation des données,\n",
    "- `tensorflow.keras` pour la construction du modèle,\n",
    "- d’autres modules spécifiques pour le prétraitement et la visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install pydot\n",
    "%pip install pydot graphviz\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.applications import EfficientNetB0 # type: ignore #ingore the warning\n",
    "from tensorflow.keras.layers import Concatenate, Input, Dense, Dropout, Flatten, GlobalAveragePooling2D # type: ignore #ingore the warning\n",
    "from tensorflow.keras.models import Model, Sequential # type: ignore #ingore the warning\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore #ingore the warning\n",
    "from tensorflow.keras.utils import plot_model # type: ignore #ingore the warning\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array # type: ignore #ingore the warning\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input # type: ignore #ingore the warning\n",
    "from tensorflow.keras.callbacks import TensorBoard # type: ignore #ingore the warning\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Détection du matériel (TPU, GPU, CPU)\n",
    "\n",
    "Cette cellule détecte le matériel disponible (TPU, GPU ou CPU) et configure une stratégie adaptée pour optimiser l'entraînement :\n",
    "\n",
    "1. **Priorité** : TPU > GPU > CPU.\n",
    "2. **Stratégie de distribution des calculs** :\n",
    "   - TPU : Utilisation de `TPUStrategy` pour exécutions distribuées.\n",
    "   - GPU : Utilisation de `MirroredStrategy` pour un ou plusieurs GPU.\n",
    "   - CPU : Stratégie par défaut si pas de TPU ou GPU disponible.\n",
    "3. **Ressources synchronisées** : Le nombre de répliques (`strategy.num_replicas_in_sync`) sera utilisé pour ajuster dynamiquement la taille globale du batch.\n",
    "\n",
    "Cette configuration optimise l'utilisation des ressources matérielles (en puissance de calcul) disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect hardware\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
    "except ValueError:\n",
    "  tpu = None\n",
    "#If TPU not found try with GPUs\n",
    "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "    \n",
    "# Select appropriate distribution strategy for hardware\n",
    "if tpu:\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "  print('Running on TPU ', tpu.master())  \n",
    "elif len(gpus) > 0:\n",
    "  strategy = tf.distribute.MirroredStrategy(gpus) # this works for 1 to multiple GPUs\n",
    "  print('Running on ', len(gpus), ' GPU(s) ')\n",
    "else:\n",
    "  strategy = tf.distribute.get_strategy()\n",
    "  print('Running on CPU')\n",
    "\n",
    "# How many accelerators do we have ?\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données\n",
    "Les données, composées d’images et de métadonnées, sont chargées depuis un fichier CSV contenant les informations associées. Ces métadonnées incluent notamment :\n",
    "- le label `benign_malignant` (notre variable cible),\n",
    "- des informations sur le patient et la lésion.\n",
    "\n",
    "L’affichage des premières lignes du fichier nous permet de vérifier sa structure et son contenu avant toute manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier CSV\n",
    "metadata = pd.read_csv(\"./images/combined_metadata.csv\")\n",
    "# Ajouter le chemin complet des images\n",
    "metadata['image_path'] = metadata['isic_id'].apply(lambda x: f\"./images/{x}.jpg\")\n",
    "\n",
    "# Encoder les labels (0 = benign, 1 = malignant)\n",
    "metadata['label'] = metadata['benign_malignant'].map({'benign': 0, 'malignant': 1})\n",
    "\n",
    "metadata = metadata.dropna(subset=['label'])\n",
    "metadata = metadata[['image_path', 'label', 'age_approx','sex']]\n",
    "print(metadata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des paramètres globaux pour l'entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins vers les fichiers TFRecord (désactivé dans cet exemple)\n",
    "# TRAINING_FILENAMES = tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords/train*')\n",
    "# TEST_FILENAMES = tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords/test*')\n",
    "\n",
    "# Taille des lots adaptée au nombre de répliques (dispositifs GPU/TPU) disponibles\n",
    "\n",
    "##################################\n",
    "# rajout conidtion si GPU ou TPU #\n",
    "##################################\n",
    "BATCH_SIZE = 10 * strategy.num_replicas_in_sync  # Par exemple, 10 images par réplique\n",
    "\n",
    "# Taille des images à utiliser (100x100 pixels)\n",
    "IMAGE_SIZE = [100, 100]  # Taille utilisée pour le redimensionnement des images\n",
    "imSize = 100             # Taille utilisée pour redimensionner les images dans les pipelines\n",
    "\n",
    "# Optimisation automatique pour le préchargement des données\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Nombre d'époques (itérations sur l'ensemble d'entraînement)\n",
    "EPOCHS = 20  # Peut être ajusté en fonction des performances et de la convergence\n",
    "\n",
    "# Définir l'entrée du modèle (couche d'entrée pour TensorFlow/Keras)\n",
    "input_layer = Input(shape=(imSize, imSize, 3))  # Entrée avec une image RGB (3 canaux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrage des données avec labels valides\n",
    "Pour garantir que seules les données pertinentes sont utilisées, nous filtrons les entrées pour ne conserver que les images ayant un label valide (`benign` ou `malignant`). Ce nettoyage est essentiel pour éviter les erreurs dans les étapes ultérieures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du fichier CSV contenant les métadonnées\n",
    "metadata = pd.read_csv(\"./images/combined_metadata.csv\")\n",
    "if metadata.isnull().any().any():\n",
    "    print(\"Des valeurs manquantes ont été détectées.\")\n",
    "    \n",
    "# Ajouter les chemins complets des images\n",
    "metadata['image_path'] = metadata['isic_id'].apply(lambda x: f\"./images/{x}.jpg\")\n",
    "\n",
    "metadata['label'] = metadata['benign_malignant'].map({'benign': 0, 'malignant': 1})\n",
    "#metadata['label'] = metadata['benign_malignant']\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes\n",
    "metadata = metadata.dropna(subset=['label'])\n",
    "\n",
    "print(f\"Nombre total d'images disponibles : {len(metadata)}\")\n",
    "print(metadata['benign_malignant'].isnull().sum())\n",
    "print(metadata['benign_malignant'].unique())\n",
    "print(f\"Total rows in original CSV: {metadata.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche le nombre  d'images par classe\n",
    "print(metadata['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division des données\n",
    "### Stratification et séparation\n",
    "Les données sont divisées en trois ensembles :\n",
    "- un ensemble d’**entraînement** (70%) pour ajuster les paramètres du modèle,\n",
    "- un ensemble de **validation** (20%) pour évaluer les performances durant la phase d'entrainement,\n",
    "- un ensemble de **test** (10%) pour mesurer la performance finale.\n",
    "\n",
    "Une stratification est appliquée pour préserver la distribution des classes dans chaque ensemble, ce qui est crucial pour une classification équilibrée et pour éviter les déséquilibres susceptibles de biaiser l'entrainement du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des ensembles en entraînement (70%), validation (20%), et test (10%)\n",
    "train_metadata, temp_metadata = train_test_split(\n",
    "    metadata, \n",
    "    test_size=0.3,  # 30 % seront partagés entre validation et test\n",
    "    stratify=metadata['label'],  # Assurer un équilibre des classes\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "val_metadata, test_metadata = train_test_split(\n",
    "    temp_metadata, \n",
    "    test_size=0.33,  # 1/3 des 30 % pour test, soit ~10 % au total\n",
    "    stratify=temp_metadata['label'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Entraînement : {train_metadata.shape[0]} exemples\")\n",
    "print(f\"Validation : {val_metadata.shape[0]} exemples\")\n",
    "print(f\"Test : {test_metadata.shape[0]} exemples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérifications des datasets\n",
    "\n",
    "Cette étape on vérifie la cohérence après la division des données :\n",
    "\n",
    "1. **Distribution des classes** : Vérification que les proportions de classes (`benign`/`malignant`) sont respectées dans chaque ensemble.\n",
    "2. **Taille totale** : Validation que la somme des échantillons des trois ensembles correspond au dataset initial.\n",
    "3. **Absence de chevauchements** : Contrôle qu’aucun échantillon ne se trouve dans plusieurs ensembles, évitant les problèmes de fuite de données (`data leakage`).\n",
    "\n",
    "Toute incohérence déclenche une erreur pour correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class distribution in training set:\")\n",
    "print(train_metadata['label'].value_counts(normalize=True))\n",
    "print(\"Class distribution in validation set:\")\n",
    "print(val_metadata['label'].value_counts(normalize=True))\n",
    "print(\"Class distribution in test set:\")\n",
    "print(test_metadata['label'].value_counts(normalize=True))\n",
    "\n",
    "total_samples = train_metadata.shape[0] + val_metadata.shape[0] + test_metadata.shape[0]\n",
    "print(f\"Total samples: {total_samples} (original: {metadata.shape[0]})\")\n",
    "\n",
    "# Check pour des overlaps entre les sets de données (data leakage), retourne une erreur si overlap\n",
    "assert len(set(train_metadata.index) & set(val_metadata.index)) == 0, \"Overlap between train and validation sets!\"\n",
    "assert len(set(val_metadata.index) & set(test_metadata.index)) == 0, \"Overlap between validation and test sets!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des fonctions pour charger et prétraiter les données\n",
    "À cette étape, le code prépare un pipeline de traitement des images pour l'entraînement du modèle. Les images sont chargées à partir de leurs chemins, redimensionnées à une taille standard de 100x100 pixels, normalisées (valeurs entre 0 et 1), et associées à leurs étiquettes (labels). Ces transformations sont encapsulées dans une fonction `load_image_and_label`, appliquée via `tf.data.Dataset` pour créer un ensemble de données TensorFlow optimisé. Enfin, les données sont divisées en lots et préchargées pour accélérer l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger et prétraiter une image\n",
    "def load_image_and_label(image_path, label):\n",
    "    \"\"\"\n",
    "    Charge une image depuis son chemin, applique des prétraitements\n",
    "    (normalisation, redimensionnement), et retourne l'image et son étiquette.\n",
    "    \"\"\"\n",
    "    # Charger l'image depuis son chemin\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)  # Décode une image JPEG en RGB\n",
    "    \n",
    "    # Normaliser les valeurs des pixels (entre 0 et 1)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    # Redimensionner l'image à une taille standard\n",
    "    image = tf.image.resize(image, [imSize, imSize])\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Fonction pour convertir un DataFrame Pandas en dataset TensorFlow\n",
    "def create_tf_dataset(metadata_df, batch_size):\n",
    "    \"\"\"\n",
    "    Convertit un DataFrame contenant les chemins des images et les labels \n",
    "    en un dataset TensorFlow optimisé pour l'entraînement.\n",
    "    \"\"\"\n",
    "    # Extraction des colonnes nécessaires depuis le DataFrame\n",
    "    image_paths = metadata_df['image_path'].values\n",
    "    labels = metadata_df['label'].values\n",
    "    \n",
    "    # Créer un dataset TensorFlow à partir des chemins et des étiquettes\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    \n",
    "    # Appliquer la fonction de chargement et de prétraitement à chaque image du dataset\n",
    "    dataset = dataset.map(load_image_and_label, num_parallel_calls=AUTO)\n",
    "    \n",
    "    # Diviser en lots et activer le préchargement pour optimiser les performances\n",
    "    dataset = dataset.batch(batch_size).prefetch(AUTO)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test d'affichage de quelques images du dataset (depuis le pipeline TensorFlow)\n",
    "Cette étape permet de vérifier si les images ont été correctement redimensionnées en prenant aléatoirement 5 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser 5 images aléatoires depuis le pipeline TensorFlow\n",
    "for image, label in create_tf_dataset(metadata.sample(frac=1).reset_index(drop=True), batch_size=1).take(5):\n",
    "    # Convertir le tenseur en tableau NumPy pour l'affichage\n",
    "    img_resized = image[0].numpy()\n",
    "    plt.imshow(img_resized)\n",
    "    # Afficher le label avec le mapping 0 -> Benign, 1 -> Malignant\n",
    "    plt.title(f\"{'Benign' if label.numpy() == 0 else 'Malignant'}\")\n",
    "    plt.axis('off')  # Supprimer les axes pour une meilleure visualisation\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction du modèle\n",
    "### Chargement du modèle pré-entraîné\n",
    "Nous utilisons `EfficientNetB0`, un modèle convolutionnel pré-entraîné sur ImageNet. Les couches internes, qui extraient les caractéristiques générales des images, sont gelées, tandis que la dernière couche de classification est remplacée pour s’adapter à notre tâche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle EfficientNetB0 préentraîné sans la couche de classification finale\n",
    "with strategy.scope():\n",
    "    base_model = tf.keras.Sequential([\n",
    "        EfficientNetB0(\n",
    "            input_shape=(imSize, imSize, 3),\n",
    "            weights='imagenet',\n",
    "            include_top=False\n",
    "        )\n",
    "    ])\n",
    "\n",
    "# Geler les couches du modèle de base pour conserver les poids préentraînés\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passer l'entrée à travers le modèle de base\n",
    "x = base_model(input_layer, training=False)  # `input_layer` \n",
    "x = Flatten()(x)  # Aplatir les caractéristiques extraites\n",
    "\n",
    "# Ajout de couches fully connected pour la classification\n",
    "x = Dense(128, activation=\"relu\")(x)  # Couche dense\n",
    "x = Dropout(0.5)(x)  # Dropout pour régularisation\n",
    "output = Dense(1, activation=\"sigmoid\")(x)  # Sigmoid pour une classification binaire\n",
    "\n",
    "# Définir le modèle final avec une seule entrée (image)\n",
    "model = Model(inputs=input_layer, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation du modèle\n",
    "\n",
    "Cette étape configure le modèle pour l’entraînement en définissant l’optimiseur, la fonction de perte et les métriques à suivre. Après la compilation, un résumé du modèle est affiché pour vérifier la structure des couches, le nombre de paramètres et la compatibilité des dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',           # Optimiseur Adam\n",
    "    loss=\"binary_crossentropy\", # Fonction de perte pour la classification binaire\n",
    "    metrics=[\"accuracy\"]        # Suivi de la précision\n",
    ")\n",
    "# Résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'architecture du modèle\n",
    "plot_model(model, show_shapes=True, to_file=\"efficientnetb0_model.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des datasets optimisés pour TensorFlow\n",
    "Cette étape transforme les sous-ensembles (entraînement, validation et test) en pipelines optimisés pour TensorFlow à l'aide de `create_tf_dataset`. Chaque dataset contient des images prétraitées (chargées, redimensionnées, et normalisées) associées à leurs labels, regroupées en lots de taille spécifiée (`BATCH_SIZE`). Ces datasets sont utilisés directement par le modèle lors de l'entraînement ou de l'évaluation pour assurer une gestion efficace des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la taille des batchs d'images\n",
    "BATCH_SIZE = max(1, len(train_metadata) // 10)\n",
    "print(f\"BATCH_SIZE : {BATCH_SIZE} batches\")\n",
    "\n",
    "# Créer les datasets\n",
    "training_dataset = create_tf_dataset(train_metadata, batch_size=BATCH_SIZE)\n",
    "validation_dataset = create_tf_dataset(val_metadata, batch_size=BATCH_SIZE)\n",
    "test_dataset = create_tf_dataset(test_metadata, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Training dataset : {len(training_dataset)} batches\")\n",
    "print(f\"Validation dataset : {len(validation_dataset)} batches\")\n",
    "print(f\"Test dataset : {len(test_dataset)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle\n",
    "### Paramètres de l'entraînement\n",
    "Les paramètres `STEPS_PER_EPOCH` et `VALIDATION_STEPS` déterminent le nombre de lots nécessaires pour parcourir une fois l'ensemble des données d'entraînement ou de validation. Ils sont calculés en divisant la taille totale des données par `BATCH_SIZE` pour garantir que le modèle traite toutes les données à chaque époque, tout en optimisant l'utilisation des ressources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des paramètres pour l'entraînement\n",
    "STEPS_PER_EPOCH = len(train_metadata) // BATCH_SIZE\n",
    "VALIDATION_STEPS = len(val_metadata) // BATCH_SIZE\n",
    "\n",
    "print(f\"Nombre total de lots pour l'entraînement : {STEPS_PER_EPOCH}\")\n",
    "print(f\"Nombre total de lots pour la validation : {VALIDATION_STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# à supprimer\n",
    "print(f\"Training samples: {len(train_metadata)}\")\n",
    "print(f\"Validation samples: {len(val_metadata)}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "print(f\"Total training batches: {len(list(training_dataset))}\")\n",
    "print(f\"Total validation batches: {len(list(validation_dataset))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduler pour le Learning Rate\n",
    "Le modèle est entraîné sur l’ensemble d’entraînement, avec un suivi sur l’ensemble de validation. Un learning rate dynamique est utilisé, évoluant selon les phases suivantes :\n",
    "1. Augmentation progressive jusqu’à un seuil maximal.\n",
    "2. Stabilisation au maximum pendant une durée définie.\n",
    "3. Réduction exponentielle jusqu’à un seuil minimal.\n",
    "\n",
    "Ce mécanisme permet une convergence optimale et une meilleure généralisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_function(epoch):\n",
    "    LR_START = 0.00001 # Taux d'apprentissage initial\n",
    "    LR_MAX = 0.00005 * strategy.num_replicas_in_sync # Taux d'apprentissage maximal\n",
    "    LR_MIN = 0.00001 # Taux d'apprentissage minimal\n",
    "    LR_RAMPUP_EPOCHS = 5 # nombre d'époques pendant lesquelles le taux d'apprentissage augmente linéairement.\n",
    "    LR_SUSTAIN_EPOCHS = 0 # nombre d'époques où le taux reste maximal\n",
    "    LR_EXP_DECAY = .8 # taux de décroissance exponentielle du taux d'apprentissage après les périodes de \"ramp-up\" et de \"soutien\"\n",
    "\n",
    "    # Augmentation (pour les premières LR_RAMPUP_EPOCHS époques) : le taux d'apprentissage commence à LR_START et monte linéairement jusqu'à LR_MAX\n",
    "    if epoch < LR_RAMPUP_EPOCHS: \n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "\n",
    "    # Soutien (pour les LR_SUSTAIN_EPOCHS suivantes) : le taux d'apprentissage reste constant à LR_MAX\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    # Décroissance (pour les époques restantes) : le taux d'apprentissage diminue exponentiellement\n",
    "    else:\n",
    "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
    "    return lr\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(learning_rate_function, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrement des logs avec TensorBoard et entraînement du modèle\n",
    "Le modèle est entraîné tout en enregistrant les métriques dans TensorBoard pour un suivi en temps réel. On note les particularités suivantes:\n",
    "- pour **TensorBoard** : Les logs sont enregistrés dans `logs/fit/model_name`, avec les histogrammes des poids activés (`histogram_freq=1`),\n",
    "- pour l'**entraînement** : Le modèle utilise les ensembles d’entraînement et de validation, avec les callbacks suivants :\n",
    "  - `lr_schedule` pour ajuster dynamiquement le learning rate.\n",
    "  - `tensorboard_callback` pour visualiser les métriques dans TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs\", \"fit\", \"model_name\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(training_dataset, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS,\n",
    "                    validation_data=validation_dataset,callbacks=[lr_schedule,tensorboard_callback],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation et analyse des performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage des courbes d'entraînement et de validation\n",
    "Cette section génère et affiche les courbes d'évolution des métriques (`accuracy` et `loss`) au fil des époques pour évaluer les performances du modèle. Cela nous permet d’analyser :\n",
    "- La convergence du modèle sur les données d'entraînement.\n",
    "- La généralisation sur les données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_training_curves(training, validation, title, subplot):\n",
    "    \"\"\"\n",
    "    Cette fonction trace les courbes d'entraînement et de validation pour une métrique donnée (par exemple, précision, perte) au fil des époques.\n",
    "    Elle configure les sous-graphiques, personnalise l'apparence et ajoute des légendes et des étiquettes pour une meilleure visualisation.\n",
    "\n",
    "    Arguments:\n",
    "        training (liste ou tableau): Les points de données d'entraînement à tracer.\n",
    "        validation (liste ou tableau): Les points de données de validation à tracer.\n",
    "        title (str): Le titre du graphique, généralement le nom de la métrique tracée.\n",
    "        subplot (int): L'index du sous-graphe à utiliser pour le graphique actuel (1 ou 2).\n",
    "    \"\"\"\n",
    "    if subplot == 1:  # set up the subplots on the first call\n",
    "        plt.subplots(figsize=(10, 10), facecolor='#F0F0F0')\n",
    "        plt.tight_layout()\n",
    "    plt.subplot(2, 1, subplot)  # S'assurer d'avoir un bon placement dans la grille (2x1)\n",
    "    plt.gca().set_facecolor('#F8F8F8')  # change the background color\n",
    "    plt.plot(training)\n",
    "    plt.plot(validation)\n",
    "    plt.title('model ' + title)\n",
    "    plt.ylabel(title)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction sur de nouvelles données\n",
    "\n",
    "Cette section utilise le modèle entraîné pour prédire la classe (`benign` ou `malignant`) d'une image donnée. L'image est prétraitée pour correspondre au format attendu par le modèle, et la classe prédite est accompagnée d'une probabilité de confiance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de prédiction\n",
    "def predict_skin_cancer(file_path):\n",
    "    \"\"\"\n",
    "    Prédire à partir des matrices Y, Cb, Cr chargées depuis un fichier.\n",
    "    \"\"\"\n",
    "    # Charger les matrices Y, Cb, Cr à partir du fichier\n",
    "    y, cb, cr = load_ycbcr_from_file(file_path)\n",
    "\n",
    "    # Préparer l'entrée pour le modèle\n",
    "    ycbcr_input = prepare_ycbcr_input(y, cb, cr)\n",
    "\n",
    "\n",
    "    # Prédiction\n",
    "    prediction = model.predict(ycbcr_input)\n",
    "\n",
    "    # Interprétation\n",
    "    if prediction[0] > 0.5:\n",
    "        return f\"Maligne (probabilité {prediction[0][0]:.2f})\"\n",
    "    else:\n",
    "        return f\"Bénigne (probabilité {1 - prediction[0][0]:.2f})\"\n",
    "\n",
    "# Exemple d'utilisation\n",
    "file_path = \"./DataBase/Matrices/ISIC_0001120_matrices.txt\"\n",
    "result = predict_skin_cancer(file_path)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
